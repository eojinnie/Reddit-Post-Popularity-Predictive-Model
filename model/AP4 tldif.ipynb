{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whlOnOt2M02H"
      },
      "source": [
        "L2-regularized logistic regression for binary or multiclass classification; trains a model (on `train.txt`), optimizes L2 regularization strength on `dev.txt`, and evaluates performance on `test.txt`.  Reports test accuracy with 95% confidence intervals and prints out the strongest coefficients for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQTT9x-6d2JI"
      },
      "outputs": [],
      "source": [
        "from scipy import sparse\n",
        "from sklearn import linear_model\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import operator\n",
        "import nltk\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4KuVSCSqlUX",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9201c8-9dc5-4691-b747-648aedff9c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python -m nltk.downloader punkt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvJM9JGCM02J"
      },
      "outputs": [],
      "source": [
        "def load_data(filename):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[2].lstrip().rstrip()\n",
        "            text = cols[3]\n",
        "\n",
        "            X.append(text)\n",
        "            Y.append(label)\n",
        "\n",
        "    return X, Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGiM8qQiJOBU"
      },
      "outputs": [],
      "source": [
        "class Classifier:\n",
        "\n",
        "    def __init__(self, feature_method, trainX, trainY, devX, devY, testX, testY, vectorizer):\n",
        "        self.feature_vocab = {}\n",
        "        self.feature_method = feature_method\n",
        "        self.min_feature_count=2\n",
        "        self.log_reg = None\n",
        "\n",
        "        self.trainY=trainY\n",
        "        self.devY=devY\n",
        "        self.testY=testY\n",
        "        \n",
        "        self.vectorizer = vectorizer\n",
        "        self.trainX = self.process(trainX, training=True)\n",
        "        self.devX = self.process(devX, training=False)\n",
        "        self.testX = self.process(testX, training=False)\n",
        "\n",
        "    # Featurize entire dataset\n",
        "    def featurize(self, data):\n",
        "        featurized_data = []\n",
        "        for text in data:\n",
        "            feats = self.feature_method(text)\n",
        "            featurized_data.append(feats)\n",
        "        return featurized_data\n",
        "\n",
        "    def process(self, X_data, training=False):\n",
        "       if training:\n",
        "           self.vectorizer.fit(X_data)\n",
        "        \n",
        "       data = self.vectorizer.transform(X_data)\n",
        "       return data\n",
        "\n",
        "\n",
        "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
        "    #def process(self, X_data, training = False):\n",
        "        \n",
        "        #data = self.featurize(X_data)\n",
        "\n",
        "        #if training:\n",
        "            #fid = 0\n",
        "            #feature_doc_count = Counter()\n",
        "            #for feats in data:\n",
        "                #for feat in feats:\n",
        "                    #feature_doc_count[feat]+= 1\n",
        "\n",
        "            #for feat in feature_doc_count:\n",
        "                #if feature_doc_count[feat] >= self.min_feature_count:\n",
        "                    #self.feature_vocab[feat] = fid\n",
        "                    #fid += 1\n",
        "\n",
        "        #F = len(self.feature_vocab)\n",
        "        #D = len(data)\n",
        "        #X = sparse.dok_matrix((D, F))\n",
        "        #for idx, feats in enumerate(data):\n",
        "            #for feat in feats:\n",
        "                #if feat in self.feature_vocab:\n",
        "                    #X[idx, self.feature_vocab[feat]] = feats[feat]\n",
        "\n",
        "        #return X\n",
        "\n",
        "\n",
        "    # Train model and evaluate on held-out data\n",
        "    def train(self):\n",
        "        (D,F) = self.trainX.shape\n",
        "        best_dev_accuracy=0\n",
        "        best_model=None\n",
        "        for C in [0.1, 1, 10, 100]:\n",
        "            self.log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
        "            self.log_reg.fit(self.trainX, self.trainY)\n",
        "            training_accuracy = self.log_reg.score(self.trainX, self.trainY)\n",
        "            development_accuracy = self.log_reg.score(self.devX, self.devY)\n",
        "            if development_accuracy > best_dev_accuracy:\n",
        "                best_dev_accuracy=development_accuracy\n",
        "                best_model=self.log_reg\n",
        "\n",
        "#             print(\"C: %s, Train accuracy: %.3f, Dev accuracy: %.3f\" % (C, training_accuracy, development_accuracy))\n",
        "\n",
        "        self.log_reg=best_model\n",
        "        \n",
        "\n",
        "    def test(self):\n",
        "        return self.log_reg.score(self.testX, self.testY)\n",
        "        \n",
        "\n",
        "    def printWeights(self, n=10):\n",
        "\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "\n",
        "        reverse_vocab=[None]*len(self.log_reg.coef_[0])\n",
        "        for k in self.feature_vocab:\n",
        "            reverse_vocab[self.feature_vocab[k]]=k\n",
        "\n",
        "        # binary\n",
        "        if len(self.log_reg.classes_) == 2:\n",
        "          weights=self.log_reg.coef_[0]\n",
        "\n",
        "          cat=self.log_reg.classes_[1]\n",
        "          for feature, weight in list(reversed(sorted(zip(feature_names, weights), key=operator.itemgetter(1))))[:n]:\n",
        "             print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
        "          print()\n",
        "\n",
        "          cat=self.log_reg.classes_[0]\n",
        "          for feature, weight in list(sorted(zip(feature_names, weights), key=operator.itemgetter(1)))[:n]:\n",
        "             print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
        "          print()\n",
        "\n",
        "        # multiclass\n",
        "        else:\n",
        "          for i, cat in enumerate(self.log_reg.classes_):\n",
        "             weights=self.log_reg.coef_[i]\n",
        "\n",
        "             for feature, weight in list(reversed(sorted(zip(feature_names, weights), key=operator.itemgetter(1))))[:n]:\n",
        "                 print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
        "             print()\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnmb-B75M02L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a76ee3f-2fef-47ba-858a-daf389005388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package opinion_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nltk.download('opinion_lexicon')\n",
        "\n",
        "from nltk.corpus import opinion_lexicon\n",
        "\n",
        "\n",
        "def binary_bow_featurize(text, vectorizer):\n",
        "    feats = {}\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    tfidf_matrix = vectorizer.transform([text])\n",
        "    word2tfidf = dict(zip(vectorizer.get_feature_names_out(), tfidf_matrix.toarray()[0]))\n",
        "\n",
        "    #To assess capitalization of text (whether title contains at least one word that's in ALLCAP)\n",
        "    ALLCAP = 0\n",
        "    exclam = 0\n",
        "    qmark = 0\n",
        "    sarc_1 = 0\n",
        "    sarc = set(['...', '??? ', ':)', ':(', 'lmao'])\n",
        "\n",
        "    # Get the positive and negative words from the opinion lexicon\n",
        "    positive_words = set(opinion_lexicon.positive())\n",
        "    negative_words = set(opinion_lexicon.negative())\n",
        "\n",
        "    # Add some custom negative words\n",
        "    negative_words |= set(['not', 'no', 'never', 'hate', 'sad', 'Not worth', 'not good'])\n",
        "    negative = 0\n",
        "    # Add some custom positive words\n",
        "    positive_words |= set(['awesome', 'fantastic', 'amazing', 'love', 'happy', 'fun', 'the best', 'finally made it'])\n",
        "    positive = 0\n",
        "\n",
        "    for word in words:\n",
        "        word_lower = word.lower()\n",
        "        tfidf_weight = word2tfidf.get(word_lower, 0)\n",
        "\n",
        "        if word in negative_words:\n",
        "          negative += tfidf_weight\n",
        "        if word in positive_words:\n",
        "          positive += tfidf_weight\n",
        "\n",
        "        if word in sarc:\n",
        "          sarc_1 = 1\n",
        "        if word == '?':\n",
        "          qmark = 1\n",
        "        if word == '!':\n",
        "          exclam = 1\n",
        "\n",
        "        if len(word) != 1 and word == word.upper():\n",
        "          ALLCAP = 1\n",
        "        word=word.lower()\n",
        "        feats[word]=1\n",
        "    length = len(words)\n",
        "\n",
        "    #Clarity\n",
        "    if length > 10 or qmark == 1:\n",
        "      feats['Clarity'] = 1\n",
        "\n",
        "    #Sarcasm\n",
        "    if exclam == 1 or sarc_1 == 1 or ALLCAP == 1:\n",
        "      feats['Sarcasm'] = 1\n",
        "\n",
        "    #Tone\n",
        "    threshold = 0.5  # You can experiment with different threshold values\n",
        "    if positive / (positive + negative) >= threshold:\n",
        "        feats['positive'] = 1\n",
        "    elif negative / (positive + negative) >= threshold:\n",
        "        feats['negative'] = 1\n",
        "    else:\n",
        "        feats['neutral'] = 1\n",
        "\n",
        "\n",
        "    #Q vs. Statement\n",
        "    if qmark == 1:\n",
        "      feats['QS'] = 1\n",
        "\n",
        "    #Capitalization\n",
        "    if ALLCAP == 1:\n",
        "      feats['allcap'] = 1\n",
        "\n",
        "\n",
        "    #Sentence Length\n",
        "    if length <= 10:\n",
        "        feats['length:0-10'] = 1\n",
        "    elif length <= 20:\n",
        "        feats['length:11-20'] = 1\n",
        "    else:\n",
        "        feats['length:20+'] = 1\n",
        "\n",
        "    \n",
        "            \n",
        "    return feats\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frVntACeM02L"
      },
      "outputs": [],
      "source": [
        "def confidence_intervals(accuracy, n, significance_level):\n",
        "    critical_value=(1-significance_level)/2\n",
        "    z_alpha=-1*norm.ppf(critical_value)\n",
        "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
        "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DN7aup_WM02L"
      },
      "outputs": [],
      "source": [
        "def run(trainingFile, devFile, testFile):\n",
        "    trainX, trainY=load_data(trainingFile)\n",
        "    devX, devY=load_data(devFile)\n",
        "    testX, testY=load_data(testFile)\n",
        "    \n",
        "    vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
        "    vectorizer.fit(trainX)\n",
        "\n",
        "    simple_classifier = Classifier(lambda text: binary_bow_featurize(text, vectorizer), trainX, trainY, devX, devY, testX, testY, vectorizer)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "    \n",
        "    lower, upper=confidence_intervals(accuracy, len(testY), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
        "\n",
        "    simple_classifier.printWeights()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptDNcOKRM02M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012fe4fe-9e77-45a5-88ec-e02d7cd06379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.564, 95% CIs: [0.468 0.661]\n",
            "\n",
            "Average\t0.135\ta\n",
            "Average\t0.072\t?\n",
            "Average\t0.068\t's\n",
            "Average\t0.067\ton\n",
            "Average\t0.064\t)\n",
            "Average\t0.062\tmake\n",
            "Average\t0.061\tnot\n",
            "Average\t0.060\tdpdr\n",
            "Average\t0.051\t(\n",
            "Average\t0.049\tstart\n",
            "\n",
            "Not popular\t0.083\ttraining\n",
            "Not popular\t0.083\t,\n",
            "Not popular\t0.059\tstargate\n",
            "Not popular\t0.058\t-\n",
            "Not popular\t0.058\thomeless\n",
            "Not popular\t0.055\tbe\n",
            "Not popular\t0.055\tdown\n",
            "Not popular\t0.053\tcode\n",
            "Not popular\t0.052\twacom\n",
            "Not popular\t0.050\tvs\n",
            "\n",
            "Popular\t0.171\twith\n",
            "Popular\t0.086\t.\n",
            "Popular\t0.080\t!\n",
            "Popular\t0.064\tclimbing\n",
            "Popular\t0.063\t]\n",
            "Popular\t0.063\t[\n",
            "Popular\t0.062\tbest\n",
            "Popular\t0.062\tof\n",
            "Popular\t0.061\tgame\n",
            "Popular\t0.057\tupload\n",
            "\n",
            "label\t0.067\ttext\n",
            "label\t0.067\toriginal\n",
            "label\t0.027\tthe\n",
            "label\t-0.000\tthanks\n",
            "label\t-0.000\tsure\n",
            "label\t-0.000\tshaving\n",
            "label\t-0.000\tright\n",
            "label\t-0.000\tplace\n",
            "label\t-0.000\tpics\n",
            "label\t-0.000\tmyself/my\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainingFile = \"train.txt\"\n",
        "devFile = \"dev.txt\"\n",
        "testFile = \"test.txt\"\n",
        "    \n",
        "run(trainingFile, devFile, testFile)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MzAV488M02M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMfHZJXKM02M"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}